[training@localhost ~]$ cd Lahasya
[training@localhost Lahasya]$ ls -l
total 192
-rw-rw-r-- 1 training training 39168 Feb 13 04:20 access_logs_400
-rw-rw-r-- 1 training training 39168 Feb 13 04:20 access_logs_400~
-rw-rw-r-- 1 training training  5728 Feb  9 17:22 Distinct.jar
-rw-rw-r-- 1 training training  4523 Feb  9 09:54 DistinctValues.jar
-rw-rw-r-- 1 training training    43 Feb 12 16:39 File1.txt
-rw-rw-r-- 1 training training    50 Feb 12 16:40 File2.txt
-rw-rw-r-- 1 training training    61 Feb 12 16:40 File3.txt
-rw-rw-r-- 1 training training  4437 Feb 13 04:00 MinMax.jar
-rw-rw-r-- 1 training training    44 Feb 10 06:07 num
-rw-rw-r-- 1 training training  4535 Feb 10 06:24 OE.jar
-rw-rw-r-- 1 training training  5435 Feb 13 04:25 partitioner.jar
-rw-rw-r-- 1 training training    43 Feb 10 05:25 Sample.txt
-rw-rw-r-- 1 training training    57 Feb  8 20:24 WC02.txt
-rw-rw-r-- 1 training training  4285 Feb 10 04:54 WC1.jar
-rw-rw-r-- 1 training training  4400 Feb  8 20:11 WC2.jar
-rw-rw-r-- 1 training training    58 Feb  8 20:22 WC2.txt
-rw-rw-r-- 1 training training  4322 Feb 10 05:17 WC.jar
-rw-rw-r-- 1 training training  2180 Feb 10 06:34 weatherData.txt
-rw-rw-r-- 1 training training  4778 Feb 13 09:14 WordCo.jar
-rw-rw-r-- 1 training training  4436 Feb 13 04:28 WS.jar
[training@localhost Lahasya]$ hadoop fs -mkdir WC/input
[training@localhost Lahasya]$ hadoop fs -copyFromLocal WC02.txt WC/input
[training@localhost Lahasya]$ hadoop jar WordCo.jar WC/input Wc/output
23/02/13 09:16:20 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
23/02/13 09:16:20 INFO input.FileInputFormat: Total input paths to process : 1
23/02/13 09:16:20 WARN snappy.LoadSnappy: Snappy native library is available
23/02/13 09:16:20 INFO snappy.LoadSnappy: Snappy native library loaded
23/02/13 09:16:20 INFO mapred.JobClient: Running job: job_202302130839_0001
23/02/13 09:16:21 INFO mapred.JobClient:  map 0% reduce 0%
23/02/13 09:16:26 INFO mapred.JobClient:  map 100% reduce 0%
23/02/13 09:16:29 INFO mapred.JobClient:  map 100% reduce 100%
23/02/13 09:16:29 INFO mapred.JobClient: Job complete: job_202302130839_0001
23/02/13 09:16:30 INFO mapred.JobClient: Counters: 32
23/02/13 09:16:30 INFO mapred.JobClient:   File System Counters
23/02/13 09:16:30 INFO mapred.JobClient:     FILE: Number of bytes read=135
23/02/13 09:16:30 INFO mapred.JobClient:     FILE: Number of bytes written=363048
23/02/13 09:16:30 INFO mapred.JobClient:     FILE: Number of read operations=0
23/02/13 09:16:30 INFO mapred.JobClient:     FILE: Number of large read operations=0
23/02/13 09:16:30 INFO mapred.JobClient:     FILE: Number of write operations=0
23/02/13 09:16:30 INFO mapred.JobClient:     HDFS: Number of bytes read=173
23/02/13 09:16:30 INFO mapred.JobClient:     HDFS: Number of bytes written=62
23/02/13 09:16:30 INFO mapred.JobClient:     HDFS: Number of read operations=2
23/02/13 09:16:30 INFO mapred.JobClient:     HDFS: Number of large read operations=0
23/02/13 09:16:30 INFO mapred.JobClient:     HDFS: Number of write operations=1
23/02/13 09:16:30 INFO mapred.JobClient:   Job Counters 
23/02/13 09:16:30 INFO mapred.JobClient:     Launched map tasks=1
23/02/13 09:16:30 INFO mapred.JobClient:     Launched reduce tasks=1
23/02/13 09:16:30 INFO mapred.JobClient:     Data-local map tasks=1
23/02/13 09:16:30 INFO mapred.JobClient:     Total time spent by all maps in occupied slots (ms)=4679
23/02/13 09:16:30 INFO mapred.JobClient:     Total time spent by all reduces in occupied slots (ms)=2703
23/02/13 09:16:30 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
23/02/13 09:16:30 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
23/02/13 09:16:30 INFO mapred.JobClient:   Map-Reduce Framework
23/02/13 09:16:30 INFO mapred.JobClient:     Map input records=3
23/02/13 09:16:30 INFO mapred.JobClient:     Map output records=8
23/02/13 09:16:30 INFO mapred.JobClient:     Map output bytes=113
23/02/13 09:16:30 INFO mapred.JobClient:     Input split bytes=116
23/02/13 09:16:30 INFO mapred.JobClient:     Combine input records=0
23/02/13 09:16:30 INFO mapred.JobClient:     Combine output records=0
23/02/13 09:16:30 INFO mapred.JobClient:     Reduce input groups=5
23/02/13 09:16:30 INFO mapred.JobClient:     Reduce shuffle bytes=135
23/02/13 09:16:30 INFO mapred.JobClient:     Reduce input records=8
23/02/13 09:16:30 INFO mapred.JobClient:     Reduce output records=5
23/02/13 09:16:30 INFO mapred.JobClient:     Spilled Records=16
23/02/13 09:16:30 INFO mapred.JobClient:     CPU time spent (ms)=1030
23/02/13 09:16:30 INFO mapred.JobClient:     Physical memory (bytes) snapshot=275173376
23/02/13 09:16:30 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=807567360
23/02/13 09:16:30 INFO mapred.JobClient:     Total committed heap usage (bytes)=256245760
[training@localhost Lahasya]$ hadoop fs -ls WC/output
ls: `WC/output': No such file or directory
[training@localhost Lahasya]$ hadoop fs -ls Wc/output
Found 3 items
-rw-r--r--   1 training supergroup          0 2023-02-13 09:16 Wc/output/_SUCCESS
drwxr-xr-x   - training supergroup          0 2023-02-13 09:16 Wc/output/_logs
-rw-r--r--   1 training supergroup         62 2023-02-13 09:16 Wc/output/part-r-00000
[training@localhost Lahasya]$ hadoop fs -cat Wc/output/part-r-00000
also,yarn	1
is,also	1
is,mapreduce	2
mapreduce,v2	1
this,is	3
[training@localhost Lahasya]$ 
