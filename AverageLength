[training@localhost ~]$ cd Lahasya
[training@localhost Lahasya]$ ls -l
total 200
-rw-rw-r-- 1 training training 39168 Feb 13 04:20 access_logs_400
-rw-rw-r-- 1 training training 39168 Feb 13 04:20 access_logs_400~
-rw-rw-r-- 1 training training  4613 Feb 13 09:28 Avg.jar
-rw-rw-r-- 1 training training  5728 Feb  9 17:22 Distinct.jar
-rw-rw-r-- 1 training training  4523 Feb  9 09:54 DistinctValues.jar
-rw-rw-r-- 1 training training    43 Feb 12 16:39 File1.txt
-rw-rw-r-- 1 training training    50 Feb 12 16:40 File2.txt
-rw-rw-r-- 1 training training    61 Feb 12 16:40 File3.txt
-rw-rw-r-- 1 training training  4437 Feb 13 04:00 MinMax.jar
-rw-rw-r-- 1 training training    44 Feb 10 06:07 num
-rw-rw-r-- 1 training training  4535 Feb 10 06:24 OE.jar
-rw-rw-r-- 1 training training  5435 Feb 13 04:25 partitioner.jar
-rw-rw-r-- 1 training training    43 Feb 10 05:25 Sample.txt
-rw-rw-r-- 1 training training    57 Feb  8 20:24 WC02.txt
-rw-rw-r-- 1 training training  4285 Feb 10 04:54 WC1.jar
-rw-rw-r-- 1 training training  4400 Feb  8 20:11 WC2.jar
-rw-rw-r-- 1 training training    58 Feb  8 20:22 WC2.txt
-rw-rw-r-- 1 training training  4322 Feb 10 05:17 WC.jar
-rw-rw-r-- 1 training training  2180 Feb 10 06:34 weatherData.txt
-rw-rw-r-- 1 training training  4778 Feb 13 09:14 WordCo.jar
-rw-rw-r-- 1 training training  4436 Feb 13 04:28 WS.jar
[training@localhost Lahasya]$ hadoop fs -mkdir AL/input
[training@localhost Lahasya]$ hadoop fs -copyFromLocal WC02.txt AL/input
[training@localhost Lahasya]$ hadoop jar Avg.jar AL/input AL/output
23/02/13 09:31:03 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
23/02/13 09:31:03 INFO input.FileInputFormat: Total input paths to process : 1
23/02/13 09:31:03 WARN snappy.LoadSnappy: Snappy native library is available
23/02/13 09:31:03 INFO snappy.LoadSnappy: Snappy native library loaded
23/02/13 09:31:04 INFO mapred.JobClient: Running job: job_202302130839_0002
23/02/13 09:31:05 INFO mapred.JobClient:  map 0% reduce 0%
23/02/13 09:31:09 INFO mapred.JobClient:  map 100% reduce 0%
23/02/13 09:31:12 INFO mapred.JobClient:  map 100% reduce 100%
23/02/13 09:31:12 INFO mapred.JobClient: Job complete: job_202302130839_0002
23/02/13 09:31:12 INFO mapred.JobClient: Counters: 32
23/02/13 09:31:12 INFO mapred.JobClient:   File System Counters
23/02/13 09:31:12 INFO mapred.JobClient:     FILE: Number of bytes read=94
23/02/13 09:31:12 INFO mapred.JobClient:     FILE: Number of bytes written=364038
23/02/13 09:31:12 INFO mapred.JobClient:     FILE: Number of read operations=0
23/02/13 09:31:12 INFO mapred.JobClient:     FILE: Number of large read operations=0
23/02/13 09:31:12 INFO mapred.JobClient:     FILE: Number of write operations=0
23/02/13 09:31:12 INFO mapred.JobClient:     HDFS: Number of bytes read=173
23/02/13 09:31:12 INFO mapred.JobClient:     HDFS: Number of bytes written=36
23/02/13 09:31:12 INFO mapred.JobClient:     HDFS: Number of read operations=2
23/02/13 09:31:12 INFO mapred.JobClient:     HDFS: Number of large read operations=0
23/02/13 09:31:12 INFO mapred.JobClient:     HDFS: Number of write operations=1
23/02/13 09:31:12 INFO mapred.JobClient:   Job Counters 
23/02/13 09:31:12 INFO mapred.JobClient:     Launched map tasks=1
23/02/13 09:31:12 INFO mapred.JobClient:     Launched reduce tasks=1
23/02/13 09:31:12 INFO mapred.JobClient:     Data-local map tasks=1
23/02/13 09:31:12 INFO mapred.JobClient:     Total time spent by all maps in occupied slots (ms)=3626
23/02/13 09:31:12 INFO mapred.JobClient:     Total time spent by all reduces in occupied slots (ms)=2527
23/02/13 09:31:12 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
23/02/13 09:31:12 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
23/02/13 09:31:12 INFO mapred.JobClient:   Map-Reduce Framework
23/02/13 09:31:12 INFO mapred.JobClient:     Map input records=3
23/02/13 09:31:12 INFO mapred.JobClient:     Map output records=11
23/02/13 09:31:12 INFO mapred.JobClient:     Map output bytes=66
23/02/13 09:31:12 INFO mapred.JobClient:     Input split bytes=116
23/02/13 09:31:12 INFO mapred.JobClient:     Combine input records=0
23/02/13 09:31:12 INFO mapred.JobClient:     Combine output records=0
23/02/13 09:31:12 INFO mapred.JobClient:     Reduce input groups=6
23/02/13 09:31:12 INFO mapred.JobClient:     Reduce shuffle bytes=94
23/02/13 09:31:12 INFO mapred.JobClient:     Reduce input records=11
23/02/13 09:31:12 INFO mapred.JobClient:     Reduce output records=6
23/02/13 09:31:12 INFO mapred.JobClient:     Spilled Records=22
23/02/13 09:31:12 INFO mapred.JobClient:     CPU time spent (ms)=900
23/02/13 09:31:12 INFO mapred.JobClient:     Physical memory (bytes) snapshot=286646272
23/02/13 09:31:12 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=808636416
23/02/13 09:31:12 INFO mapred.JobClient:     Total committed heap usage (bytes)=256245760
[training@localhost Lahasya]$ hadoop fs -ls AL/output
Found 3 items
-rw-r--r--   1 training supergroup          0 2023-02-13 09:31 AL/output/_SUCCESS
drwxr-xr-x   - training supergroup          0 2023-02-13 09:31 AL/output/_logs
-rw-r--r--   1 training supergroup         36 2023-02-13 09:31 AL/output/part-r-00000
[training@localhost Lahasya]$ hadoop fs -cat AL/output/part-r-00000
a	4.0
i	2.0
m	9.0
t	4.0
v	2.0
y	4.0
[training@localhost Lahasya]$ 
